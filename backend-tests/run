#!/bin/bash

HERE=$(dirname $(readlink -f "$0"))
INTEGRATION_PATH=$(dirname "$HERE")
export INTEGRATION_PATH

DOWNLOAD_REQUIREMENTS="true"

COMPOSE_CMD_BASE="docker-compose -p backend-tests \
        -f $INTEGRATION_PATH/backend-tests/docker/docker-compose.backend-tests.yml
        "
COMPOSE_CMD_OPEN="docker-compose -p backend-tests \
        -f $INTEGRATION_PATH/docker-compose.yml \
        -f $INTEGRATION_PATH/docker-compose.demo.yml \
        -f $INTEGRATION_PATH/docker-compose.connect.yml \
        -f $INTEGRATION_PATH/docker-compose.config.yml \
        -f $INTEGRATION_PATH/docker-compose.storage.minio.yml
        -f $INTEGRATION_PATH/extra/integration-testing/docker-compose.yml
        -f $INTEGRATION_PATH/backend-tests/docker/docker-compose.backend-tests.yml
        "
COMPOSE_CMD_ENTERPRISE="${COMPOSE_CMD_OPEN} \
        -f $INTEGRATION_PATH/docker-compose.enterprise.yml \
        -f $INTEGRATION_PATH/extra/recaptcha-testing/tenantadm-test-recaptcha-conf.yml \
        -f $INTEGRATION_PATH/extra/smtp-testing/workflows-worker-smtp-test.yml \
        -f $INTEGRATION_PATH/extra/stripe-testing/stripe-test.docker-compose.yml
        -f $INTEGRATION_PATH/docker-compose.monitor.yml \
        -f $INTEGRATION_PATH/docker-compose.auditlogs.yml
        -f $INTEGRATION_PATH/docker-compose.auditlogs.connect.yml
        "
COMPOSE_CMD=""

PYTEST_FILTER_OPEN="not Enterprise and not Multitenant"
PYTEST_FILTER_ENTERPRISE="Enterprise"
PYTEST_FILTER=""

PYTEST_REPORT_OPEN="--self-contained-html \
        --junit-xml=results_backend_integration_open.xml \
        --html=report_backend_integration_open.html"
PYTEST_REPORT_ENTERPRISE="--self-contained-html \
        --junit-xml=results_backend_integration_enterprise.xml \
        --html=report_backend_integration_enterprise.html"
PYTEST_REPORT=""

TOOLS="$INTEGRATION_PATH/backend-tests/downloaded-tools"

usage() {
    echo "runner script for backend-specific integration tests"
    echo ""
    echo "./backend-tests"
    echo -e "\t-h --help"
    echo -e "\t-s --suite <SUITE>\trun specific test suite"
    echo -e "\t                  \t<SUITE> can be 'open' (default), 'enterprise', 'all'"
    echo -e "\t--no-download     \tdo not download the external dependencies"
    echo -e "\t-c --skip-cleanup \tleave containers running after tests"
    echo -e "\t other args will be passed to the testing container's py.test command"
    echo ""
    echo -e "examples:"
    echo -e "run default ST setup:"
    echo -e "\t./run"
    echo -e "run tests Enterprise tests"
    echo -e "\t./run -s enterprise"
    echo -e "run specific test TestGetDevices in both setups"
    echo -e "\t./run -s all -k TestGetDevices"
}

TEST_SUITES=( "open" )
parse_args(){
    while [ $# -gt 0 ]; do
        case "$1" in
            -h | --help)
                usage
                exit
                ;;
            -s | --suite)
                shift 1
                case "$1" in
                    open)
                        ;;
                    enterprise)
                        TEST_SUITES=( "enterprise" )
                        ;;
                    all)
                        TEST_SUITES=( "open" "enterprise" )
                        ;;
                    *)
                        usage
                        exit
                        ;;
                esac
                ;;
            -f | -f=*)
                usage
                exit 1
                ;;
            --no-download)
                DOWNLOAD_REQUIREMENTS=""
                ;;
            -c | --skip-cleanup)
                SKIP_CLEANUP=1
                ;;
            --)
                shift 1
                USER_PYTEST_ARGS="$USER_PYTEST_ARGS $@"
                return 0
                ;;
            *)
                USER_PYTEST_ARGS="$USER_PYTEST_ARGS $1"
                ;;
        esac
        shift 1
    done
}

build_backend_tests_runner() {
    mkdir -p "$TOOLS"

    if [[ -n "$DOWNLOAD_REQUIREMENTS" ]]; then
        get_runner_requirements
    fi

    docker build -t mender-backend-tests-runner -f $INTEGRATION_PATH/backend-tests/docker/Dockerfile $INTEGRATION_PATH/backend-tests
}

get_runner_requirements() {
    local MENDER_ARTIFACT_PATH="$TOOLS/mender-artifact"
    local MENDER_ARTIFACT_BRANCH=$($INTEGRATION_PATH/extra/release_tool.py --version-of mender-artifact)

    if [ ! -f "$MENDER_ARTIFACT_PATH" ]; then
        echo "downloading mender-artifact/$MENDER_ARTIFACT_BRANCH"
        curl -s --fail "https://downloads.mender.io/mender-artifact/${MENDER_ARTIFACT_BRANCH}/linux/mender-artifact" \
             -o "$MENDER_ARTIFACT_PATH"
        chmod +x "$MENDER_ARTIFACT_PATH"
    fi
}

run_tests() {
    local RUN_ARGS="--use-aliases"
    # Need to start the backend first
    $COMPOSE_CMD up --scale mender-backend-tests-runner=0 -d --remove-orphans
    if [ -n "$AZURE_IOTHUB_CONNECTIONSTRING" ]; then
        RUN_ARGS="${RUN_ARGS} -e AZURE_IOTHUB_CONNECTIONSTRING=${AZURE_IOTHUB_CONNECTIONSTRING}"
    fi
    # ... then the runner
    $COMPOSE_CMD run $RUN_ARGS mender-backend-tests-runner
    return $?
}

copy_test_reports_if_args() {
    while [ -n "$1" ]; do
        case "$1" in
            --junit-xml=*)
                RESULTS_FILE="${1#--junit-xml=}"
                ;;
            --junit-xml)
                shift
                RESULTS_FILE="$1"
                ;;
            --html=*)
                REPORT_FILE="${1#--html=}"
                ;;
            --html)
                shift
                REPORT_FILE="$1"
                ;;
        esac
        shift
    done

    cid=$($COMPOSE_CMD ps -aq mender-backend-tests-runner | head -n 1)
    if [ -n "$RESULTS_FILE" ]; then
        echo "-- copying file $RESULTS_FILE"
        docker cp ${cid}:/$RESULTS_FILE . || true
    fi
    if [ -n "$REPORT_FILE" ]; then
        echo "-- copying file $REPORT_FILE"
        docker cp ${cid}:/$REPORT_FILE . || true
    fi
}

prepare_pytest_args() {
    PYTEST_ARGS=""
    filter="none"
    for val in $USER_PYTEST_ARGS; do
        if [ "$val" == "-k" ]; then
            filter="next"
        elif [ "$filter" == "next" ]; then
            PYTEST_FILTER="$PYTEST_FILTER and $val"
            filter="done"
        else
            PYTEST_ARGS="$PYTEST_ARGS $val"
        fi
    done

    echo "-- using PYTEST_FILTER=$PYTEST_FILTER"
    PYTEST_ARGS="$PYTEST_ARGS -k '$PYTEST_FILTER' $PYTEST_REPORT"

    export PYTEST_ARGS
}

cleanup(){
    if [ -z $SKIP_CLEANUP ]; then
        $COMPOSE_CMD down -v --remove-orphans
    else
        # Remove stopped container created by docker-compose run
        $COMPOSE_CMD rm -f
    fi
}

parse_args "$@"
build_backend_tests_runner

script_failed=0

for suite in "${TEST_SUITES[@]}"; do
    case "$suite" in
        open)
            COMPOSE_CMD="$COMPOSE_CMD_OPEN"
            PYTEST_FILTER="$PYTEST_FILTER_OPEN"
            PYTEST_REPORT="$PYTEST_REPORT_OPEN"
            ;;
        enterprise)
            COMPOSE_CMD="$COMPOSE_CMD_ENTERPRISE"
            PYTEST_FILTER="$PYTEST_FILTER_ENTERPRISE"
            PYTEST_REPORT="$PYTEST_REPORT_ENTERPRISE"
            ;;
    esac

    if [ -n "$K8S" ]; then
        COMPOSE_CMD="${COMPOSE_CMD_BASE}"
    fi

    prepare_pytest_args
    run_tests
    run_tests_retcode=$?
    if [ $script_failed -eq 0 ]; then
        script_failed=$run_tests_retcode
    fi

    if [ $? != 0 ]; then
        tmppath=$(mktemp ${HERE}/acceptance.XXXXXX)
        echo "-- tests failed, dumping logs to $tmppath"
        $COMPOSE_CMD logs > $tmppath
    fi

    copy_test_reports_if_args $PYTEST_REPORT

    cleanup

done

exit $script_failed
